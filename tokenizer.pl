#!/usr/bin/perl
#
# $Id: tokenizer.pl,v 1.9 2013/11/05 14:24:29 ads Exp ads $
#
# This program is part of the NASA Astrophysics Data System
# abstract service loading/indexing procedure.
#
# Copyright (C): 1994, 1995 Smithsonian Astrophysical Observatory.
# You may do anything you like with this file except remove
# this copyright.  The Smithsonian Astrophysical Observatory
# makes no representations about the suitability of this
# software for any purpose.  It is provided "as is" without
# express or implied warranty.  It may not be incorporated into
# commercial products without permission of the Smithsonian
# Astrophysical Observatory.
#
#
# Indexing tokenizer
# 
# $Log: tokenizer.pl,v $
# Revision 1.9  2013/11/05 14:24:29  ads
# Limited affiliation field length to 1M characters
#
# Revision 1.8  2011/10/07 14:54:08  ads
# Added PACS kwyword indexing, more tweaks to the transliteration of russian names,
# Properly handling of keyword case.
#
# Revision 1.7  2010/04/02 00:38:36  ads
# Implemented new author parsing/synonyming rules.
#
# Revision 1.6  2010/03/16 20:53:34  ads
# Added exact author indexing (delayed checkin)
#
# Revision 1.5  2005/12/27 20:12:24  ads
# Reworked exact author parsing to create synonym file for composite
# characters on the fly; added trailing comma to last name only entries
#
# Revision 1.4  2004/01/27 18:29:36  ads
# Modified author parsing to remove all non-alpha characters
#
# Revision 1.3  2003/11/08 02:54:37  ads
# Rewritten from scratch to use the object-oriented approach
# implemented in the ADS::Abstracts::Index::Tokenizer package.
#
# Revision 1.2  2003/07/01 20:15:14  ads
# Script is now using SplitAffiliation from ADS::Abstracts::Utils
#
# Revision 1.1  2003/05/21 18:54:32  ads
# Initial revision
#
#
#

use Data::Dumper;
use ADS::Abstracts::IO;
use ADS::Abstracts::Utils;
use ADS::Abstracts::Index;
use ADS::Abstracts::Index::Tokenizer;
use ADS::Abstracts::Entities;

(my $script = $0) =~ s:^.*/::g;
use integer;
use strict;
use warnings;

my $sourcedir = ".";
my $destdir   = ".";
my $configdir = ".";
my $absext = ".abs";
my $asynfile = "author.syn.auto";
my $usage = <<"EOF";
Usage: $script [OPTIONS] field [...] < accno_list
where field [...] is the name of a field to be indexed and OPTIONS are:
    --debug            turn debuggin on
    --debug-pipe       debug output to text pipe by sending it to output file
    --author-syn FILE  write autogenerated author synonyms to FILE
                       (default: $asynfile)
    --configdir DIR    directory where field-specific config files are found
                       (default: $configdir)
    --destdir DIR      directory where output files are written
                       (default: $destdir)
    --sourcedir DIR    top-level directory for accno text files
                       (default: $sourcedir)
EOF
    ;

my $ascii_enc = ADS::Abstracts::Entities::Recoder->new(Format => 'Text') or
    die __PACKAGE__, ": cannot create ascii encoder!";

select(STDERR); $| = 1; select(STDOUT); $| = 1;
my $debug = 0;
my $debug_pipe = 0;

# truncate abstracts longer than 10K characters, affiliations longer than 1M
my $MAX_ABS_LENGTH = 10240;
my $MAX_AFF_LENGTH = 1024 * 1024;

sub pdebug { 1 }
while (@ARGV and $ARGV[0] =~ /^--/) {
    local $_ = shift(@ARGV);
    if (/^--sourcedir/) {
	$sourcedir = shift(@ARGV) or
	    die "$script: argument required for option $_";
    } elsif ($_ eq '--debug-pipe') {
	$debug_pipe = 1;
    } elsif (/^--destdir/) {
	$destdir = shift(@ARGV) or
	    die "$script: argument required for option $_";
    } elsif (/^--configdir/) {
	$configdir = shift(@ARGV) or
	    die "$script: argument required for option $_";
    } elsif (/^--author-syn/) {
	$asynfile = shift(@ARGV) or
	    die "$script: argument required for option $_";
    } elsif (/^--debug-pipe/) {
	$debug_pipe = 1;
    } elsif (/^--debug/) {
	undef &pdebug; 
	eval 'sub pdebug { print STDERR "$script: ", @_; }';
	$debug = 1;
    } elsif (/^--help/) {
	die $usage;
    } else {
	die "$script: unknown option $_\n", $usage;
    }
}


# these are the options that control the tokenization of the different fields
my $index_opts = {
    author      => { 
	splitfunc => \&ADS::Abstracts::Utils::SplitAuthors,
	upcase    => 1,
    },
    object      => {
	splitfunc => \&ADS::Abstracts::Utils::SplitOnComma,
	upcase    => 1,
    },
    object_LPI  => {
	splitfunc => \&ADS::Abstracts::Utils::SplitOnComma,
	upcase    => 1,
	absfield  => 'OBJ-LPI',
    },
    object_IAU  => { 
	splitfunc => \&ADS::Abstracts::Utils::SplitOnComma,
	upcase    => 0,
	absfield  => 'OBJ-IAU',
    },
    affiliation => {
	splitfunc => sub { 
	    ADS::Abstracts::Utils::SplitAffiliation($_[0],canonize => 1)
	    },
	upcase    => 1,
	absfield  => 'AFF',
    },
    keyword     => {
	splitfunc => \&ADS::Abstracts::Utils::SplitOnComma,
	upcase    => 0,
    },
    pacs        => {
	splitfunc => \&ADS::Abstracts::Utils::SplitOnComma,
        absfield  => 'PACS',
    }, 
    pacskwds      => {
	splitfunc => \&ADS::Abstracts::Utils::SplitOnComma,
        absfield  => 'KWD-PACS',
    }, 
    title       => {
	splitfunc => \&ADS::Abstracts::Utils::SplitText,
	class     => 'ADS::Abstracts::Index::Tokenizer::Text',
    },
    text        => {
	splitfunc => \&ADS::Abstracts::Utils::SplitText,
	class     => 'ADS::Abstracts::Index::Tokenizer::Text',
    },
};  


# TODO: sanity checks
die "$script: no arguments specified!\n", $usage unless (@ARGV);

my $tokenizer = {};

# the command-line arguments tell us what fields should be indexed
my %index = (); 
while (@ARGV) {
    local $_ = shift(@ARGV);
    unless ($index_opts->{$_}) {
	warn "$script: dunno how to create '$_' index, skipping it\n";
	next;
    }
    $index{$_}++;
}

# now set up the tokenizer fields
foreach my $f (keys %$index_opts) {

    my $splitfunc = $index_opts->{$f}->{splitfunc};
    warn "$script: warning: not splitword function defined for field \"$f\"\n"
	unless (defined($splitfunc));
    my $class = $index_opts->{$f}->{class} ||
        'ADS::Abstracts::Index::Tokenizer';
    my $upcase = $index_opts->{$f}->{upcase};

    my $t = $class->new(field      => $f,
			configdir  => $configdir, 
			destdir    => $destdir,
			upcase     => $upcase,
			splitwords => $splitfunc,
			debug      => $debug,
			debug_pipe => $debug_pipe) or
	die "$script: error setting up tokenizer for field $f";
    $tokenizer->{$f} = $t;

}

warn "$script: starting parsing on ", scalar localtime(time), "\n";
# open abstract codes file
open(my $abscodes, ">> abstract_codes.accnos") or 
    die "$script: cannot open output file abstract_codes.accnos";

# these are used for author synonyms
my $group = 0;
my $agroup = {};
my $alist = [];
my $newauthsyn = 0;
($group,$agroup,$alist) = ADS::Abstracts::Index::readsyns($asynfile) 
    if (-f $asynfile);

while (<STDIN>) {
    chop;
    my ($id,$absfile) = split;
    if (not $id or not $absfile) { 
	warn "$script: warning: line $.: botched entry: \"$_\" (skipped)\n";
	next;
    } elsif (not -f $absfile) {
	warn "$script: warning: line $.: id $id: file \"$absfile\" does ",
	"not exist (skipped)\n";
	next;
    }
    my $field = ReadAbs($absfile);
    unless ($field) {
	warn "$script: warning: cannot read fields from \"$absfile\" ",
	"(skipped)\n";
	next;
    }

    &pdebug("Indexing document $id, file $absfile\n");
    &pdebug("$id: abstract hash is ", Data::Dumper->Dump([ $field ]), "\n");

    my @title = $tokenizer->{title}->tokenize($field->{XTL});
    
    if ($index{title} and @title) {
	$tokenizer->{title}->write($id,@title) or
	    warn "$script: $absfile: error writing title field\n";
    } elsif ($debug and not @title) {
	warn "$script: $absfile: no title found\n";
    }

    my @keywords = $tokenizer->{keyword}->tokenize(map { $field->{$_} }
						   grep(/^KWD/,keys(%$field)));
    if ($index{keyword} and @keywords) {
	$tokenizer->{keyword}->write($id, map { uc($_) } @keywords) or
	    warn "$script: $absfile: error writing keyword field\n";
    } elsif ($debug and not @keywords) {
	warn "$script: $absfile: no keywords found\n";
    }
	
    my @objects = $tokenizer->{object}->tokenize(map { $field->{$_} }
						 grep(/^OBJ/,keys(%$field)));

    if ($index{text}) {
	my @abstract = ();
	if (defined($field->{ABS}) and $field->{ABS} =~ /\S/ and
	    $field->{ABS} !~ /^\s*not\s+available\.?\s*$/i) {
	    if (length($field->{ABS}) > $MAX_ABS_LENGTH) {
		$field->{ABS} = substr($field->{ABS},0,$MAX_ABS_LENGTH);
		warn "$script: $absfile: abstract too long, truncated at $MAX_ABS_LENGTH\n";
	    }
	    @abstract = $tokenizer->{text}->tokenize($field->{ABS});
	    print $abscodes $id, "\n";

	} elsif ($debug) {
	    warn "$script: absfile: no abstract found\n";
	}
	my @comments = map { $field->{$_} } grep(/^COM/,keys(%$field));

	# abstract, title, comments, keywords and object names are all 
	# indexed in the text field, but each one is passed as separate
	# array elements so that phrase searches don't span across fields
	$tokenizer->{text}->write($id,@abstract,
				  @title,@keywords,@objects,@comments) or
	    warn "$script: $absfile: error writing text field\n";
    }
    
    # authors
    if ($index{author}) {
	pdebug("indexing field author\n");
	my @authors;
	foreach ($field->{AUT},$field->{RAU},$field->{BAU}) {
	    next unless ($_);
	    # Author preprocessing: apply general transformations
	    # to concatenated author strings.  Individual author name
	    # manipulation happens later.  Here we deal with the 
	    # transformations necessary to create synonyms for 
	    # umlauts, slashes, carons, and SAINT/ST.  This is done by
	    # inserging "_" between characters that will be deleted
	    # later on when creating synonyms, as follows:
	    #     XXX_YYY_ZZZ => XXXYYYZZZ, XXXZZZ
	    s/\&([A-DF-Za-df-z])uml\;/${1}_E_/g;
	    s/\&([Oo])slash\;/${1}_E_/g;
# this is already taken care of by the ascii recoding below
#	    s/\&([AOao])elig\;/${1}_E_/g;
	    s/\&([Aa])ring\;/${1}_A_/g;
	    s/\&([CcSsZz])caron\;/${1}_H_/g;
	    $_ = $ascii_enc->recode($_);
	    s/\bSAINT\b/S_AIN_T/gi;
	    $_ = uc($_);
	    s/[^A-Z0-9_\,\;\']+/ /gi;
	    s/\s*\,\s*/, /g;
	    s/\s+/ /g;
	    s/\A\s+|\s+\Z//g;
	    next unless ($_);
	    push(@authors, split(/\s*\;\s*/,uc($_)));
	}

	# create automatic synonyms from current exact author field
	foreach my $a (@authors) {
	    pdebug("considering author string \"$a\"\n");
	    # if this is a lastname only, append comma
	    $a .= ',' unless ($a =~ /\,/);

	    # take care of russian apostrophes:
	    # 'E == E == IE == YE
	    # note that we do not index 'E since the search
	    # engine simply strips all apostrophes
	    $a =~ s/(\w\w)\'E/$1.E/g;
	    $a =~ s/\'//g;

	    my $b = $a;
	    my @synonyms;
	    my @nsyns;
	    if ($a =~ s/_([A-Z]+?)_/$1/g) { 
		$b =~ s/_([A-Z]+?)_//g;
		push(@synonyms, $b);
		pdebug("generated synonym pair \"$a\", \"$b\"\n");
	    }

	    # see above for russian apostrophe rules
	    if ($a =~ /\./) {
		@nsyns = ($a, @synonyms);
		foreach $b (@nsyns) {
		    $b =~ s/\./I/g;
		    push(@synonyms, $b);
		}
		@nsyns = ($a, @synonyms);
		foreach $b (@nsyns) {
		    $b =~ s/\./Y/g;
		    push(@synonyms, $b);
		}
		$a =~ s/\.//g;
		pdebug("generated synonym tuple ", 
		       (map { "\"$_\", " } @synonyms),
		       "\"$a\"\n");
	    } else {
		push(@synonyms, $a);
	    }
	    $b = $a;

	    # russian last names I:
	    # [^IJY]EV$ == IEV$ == YEV$ == JEV$ 
	    # [^IJY]EVA$ == IEVA$ == YEVA$ == JEVA$ 
	    if ($b =~ /\A(.*[^IJY])(EVA?,.*)\Z/) {
		push(@synonyms, "$1I$2", "$1Y$2", "$1J$2");
		pdebug("generated synonym tuple \"$a\", ",
		       "\"$1I$2\", \"$1Y$2\", \"$1J$2\"\n");
	    }
	    # russian last names II:
	    # ([NRBO])IA$ == $1IIA$ == $1IYA$
	    if ($b =~ /\A(.*[NRBO]I)(A,.*)\Z/) {
		push(@synonyms, "$1I$2", "$1Y$2");
		pdebug("generated synonym tuple \"$a\", ",
		       "\"$1I$2\", \"$1Y$2\"\n");
	    }
	    # russian last names III:
	    # ([DHKLMNPSZ])IAN$ == $1YAN$ == $1JAN$ 
	    if ($b =~ /\A(.*[DHKLMNPSZ])[IJY](AN,.*)\Z/) {
		push(@synonyms, "$1I$2", "$1Y$2", "$1J$2");
		pdebug("generated synonym tuple \"$a\", ",
		       "\"$1I$2\", \"$1Y$2\", \"$1J$2\"\n");
	    }
	    # russian last names IV:
	    # AIA$ == AYA$ == AJA$ 
	    if ($b =~ /\A(.*[KNV]A)[IJY](A,.*)\Z/) {
		push(@synonyms, "$1I$2", "$1Y$2", "$1J$2");
		pdebug("generated synonym tuple \"$a\", ",
		       "\"$1I$2\", \"$1Y$2\", \"$1J$2\"\n");
	    }
	    # russian last names V:
	    # KI$ == KII$ == KIJ$ == KIY$ = KYI$
	    # VI$ == VII$ == VIJ$ == VIY$ = VYI$
	    # first transform [KVH]I into [KVH]II
	    if ($b =~ s/\A(.*[KV]I)(,.*)\Z/$1I$2/) {
		push(@synonyms, "$1I$2");
		pdebug("generated synonym pair \"$a\", ",
		       "\"$1I$2\"\n");
	    }
	    # now apply synonym rules dealing with the above
	    if ($b =~ /\A(.*[KV])I[IJY](,.*)\Z/) {
		push(@synonyms, "$1II$2", "$1IJ$2", "$1IY$2", "$1YI$2", 
		     "$1I$2", "$1Y$2");
		pdebug("generated synonym tuple \"$a\", ",
		       "\"$1II$2\", \"$1IJ$2\", \"$1IY$2\", \"$1YI$2\"",
		       "\"$1I$2\", \"$1Y$2\"\n");
	    }
	    # russian first name synonyming
	    # ^IU == ^YU
	    # ^IA == ^YA
	    @nsyns = ();
	    foreach $b (@synonyms) {
		if ($b =~ /\A(.*, )[IY]([AU].*)/) {
		    push(@nsyns, "$1I$2", "$1Y$2");
		    pdebug("generated synonym pair ",
			   "\"$1I$2\", \"$1Y$2\"\n");
		}
	    }
	    push(@synonyms,@nsyns);

	    next unless ($a =~ /\w/);
	    # if there is just one term, no need to continue
	    next unless (@synonyms);

	    # unique synonym list and see if there are already
	    # synonym groups associated with any of these names
	    my %gash;
	    foreach $b ($a, @synonyms) {
		$gash{$b} = $agroup->{$b} || 0;
	    }

	    my $gno = 0;
	    my $g;
	    @synonyms = ();
	    foreach $b (sort keys %gash) {
		if (not $gash{$b}) {
		    push(@synonyms, $b);
		} elsif ($gno and $gno ne $gash{$b}) {
		    warn "$id: warning: group for \"$g\" is ", $gno,
		    " group for \"$b\" is ", $gash{$b}, " (ignored)\n";
		} else {
		    push(@synonyms, $b);
		    $gno = $gash{$b};
		    $g = $b;
		}
	    }
	    # if there is just one term, no need to continue
	    next unless ($#synonyms > 0);

	    my @new;
	    if ($gno) {
		# group exists already; only issue warning if
		# we are merging some synonyms that do not already
		# exist in the group
		foreach $b (@synonyms) {
		    push(@new, $b) unless ($agroup->{$b});
		}
		if (@new) {
		    my @old = @{$alist->[$gno]};
		    warn "$id: warning: merging ", (map { "\"$_\", " } @new), 
		    " in group $gno: ", (map { "\"$_\", " } @old), "\n";
		}
	    } else {
		$newauthsyn++; $group++;
		$gno = $group;
		@new = @synonyms;
		warn "$id: created new group for ",
		(map { "\"$_\", " } @synonyms), ": $gno\n";
	    }
	    # now add them to $agroup hash and $alist array
	    foreach $b (@synonyms) {
		$agroup->{$b} = $gno;
	    }
	    my $al = $alist->[$gno] || [];
	    $alist->[$gno] = [ sort(@{$al}, @new) ];

	}
	# finally write the authors out to the index
	if (@authors and $index{author}) {
	    $tokenizer->{author}->write($id,@authors) or 
		warn "$script: $absfile: error writing author field\n";
	} 
    }

    # affiliation has special handling due to error reporting
    if ($index{affiliation} and defined($field->{AFF}) and $field->{AFF}) {
	my $t = $tokenizer->{affiliation};
	if (length($field->{AFF}) > $MAX_AFF_LENGTH) {
	    $field->{AFF} = substr($field->{AFF},0,$MAX_AFF_LENGTH);
	    warn "$script: $absfile: affiliation too long, truncated at $MAX_AFF_LENGTH\n";
	}
	$t->write($id,$t->tokenize({ AFF => $field->{AFF}, id => $id })) or
	    warn "$script: $absfile: error writing affiliation field\n";
    }

    if ($index{object_LPI} and defined($field->{'OBJ-LPI'}) 
	and $field->{'OBJ-LPI'}) {
	my $text = $field->{'OBJ-LPI'};
	my $t = $tokenizer->{object_LPI};
	$t->write($id,$t->tokenize($text)) or
	    warn "$script: $absfile: error writing object_LPI field\n";
    }

    # IAU object is a special case since some fields have multiple
    # object names separated by "=", so we split them up here
    if ($index{object_IAU} and defined($field->{'OBJ-IAU'}) 
	and $field->{'OBJ-IAU'}) {
	my $text = $field->{'OBJ-IAU'};
	$text =~ s/\s+\=\s+/; /g;
	my $t = $tokenizer->{object_IAU};
	$t->write($id,$t->tokenize($text)) or
	    warn "$script: $absfile: error writing object_IAU field\n";
    }	

    if ($index{pacs} and defined($field->{'PACS'}) and $field->{'PACS'}) {
	my $t = $tokenizer->{pacs};
	$t->write($id,$t->tokenize($field->{'PACS'})) or
	    warn "$script: $absfile: error writing PACS codes field\n";
    }

    if ($index{pacskwds} and defined($field->{'KWD-PACS'}) and $field->{'KWD-PACS'}) {
	my $t = $tokenizer->{pacskwds};
	$t->write($id,$t->tokenize(lc($field->{'KWD-PACS'}))) or
	    warn "$script: $absfile: error writing PACS keywords field\n";
    }

    # finally, print out accno (this may be used to verify that 
    # file has been successfully processed)
    print join("\t",$id,$absfile,time), "\n";

}

# now write out auto-generated author synonyms
if ($newauthsyn) {
    my $n = ADS::Abstracts::Index::writesyns($asynfile,$agroup);
    warn "$script: written $n synonyms to file $asynfile ($newauthsyn new)\n";
}

close($abscodes);
warn "$script: parsing ended on ", scalar localtime(time), "\n";
